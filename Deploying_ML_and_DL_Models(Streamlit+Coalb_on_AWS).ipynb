{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aysedata/ML-model-deployment/blob/main/Deploying_ML_and_DL_Models(Streamlit%2BCoalb_on_AWS).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        " <center> <h2 style=\"background-color:orange; color:white\" ><br> Deploying Machine Learning and Deep Learning Models<br></h2>"
      ],
      "metadata": {
        "id": "8gUHSP1SOdSa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "|Batch Processing or Ofline Batch Processing | Real Time |\n",
        "|----|-----|\n",
        "|Working ofline | real time|\n",
        "|We have train and test test | speed and feasibility is required|\n",
        "|time not a issue | time is crusial|\n",
        "\n",
        "\n",
        "\n",
        "### Deploying ML Model using `Streamlit and Google Colab`\n",
        "1. Build Loan Eligibility Application\n",
        "2. Intro to Streamlit => a web development framework\n",
        "3. Deploy ML model using Streamlit and Google Colab\n",
        "\n",
        "### Deploy ML model using `Streamlit and AWS`\n",
        "1. Intro to AWS\n",
        "    * setup AWS server\n",
        "2. Deploy ML model using Streamlit and AWS\n",
        "\n",
        "### Deploy Image classification model using Streamlit and AWS\n",
        "1. Build Image Classification Model\n",
        "2. Deploy model using Streamlit and AWS\n",
        "\n",
        "### Deploy Text Generation model using `Streamlit and AWS`\n",
        "1. Build Text Generation model\n",
        "2. Deploy model using Streamlit and AWS\n",
        "\n",
        "### `Amazon Sagemaker` for model deployment\n",
        "1. Intro Amazon Sagemaker\n",
        "2. Setting up Amazon Sagemaker\n",
        "3. Build a Cardiac Arrest Predictor\n",
        "4. Deploy model using Amazon Sagemaker\n",
        "\n",
        "### `Deploy Models using API's`\n",
        "1. Overview of Flask\n",
        "2. Understanding API's\n",
        "3. Deploy model using `Flask`\n",
        "4. Deploy deep learning model using `Flask`\n"
      ],
      "metadata": {
        "id": "Yn-3V8TXOdSc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Project's to Deploy<br></h4>\n",
        "\n",
        "|Project | Description|\n",
        "|-------|-------|\n",
        "|Loan Eligibility Application(Finance Industry -Tabular Data) | Building an application to automate Loan Eligibility process for a Bank|\n",
        "|Cardiac Arrest Prediction(HealthCare Industry -Tabular Data) | Building an application where users can check their chances of having a cardiac arrest|\n",
        "|Image Classification(Computer Vision Domain -Unstructured Data) | Using a Pre-trained model to Classify Images into different categories|\n",
        "|Typing Tutor(NLP Domain -Unstructured Data)  |Using a text generation model to generate code and then analyze typing speed|\n",
        "|Transcript Generation | Generating Transcript for videos and Deploying that model using `Flask`|\n",
        "</center>"
      ],
      "metadata": {
        "id": "TVVQb-P7OdSd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Tools Covered-(Model Deployment)<br></h4></center>\n",
        "\n",
        "\n",
        "1. `Google Colab`\n",
        "2. `Streamlit` => opensource app framework\n",
        "3. `AWS` => cloude computing service\n",
        "4. `Amazone Sagemaker` => ML Service by amazon\n",
        "    * Used to Build, Train and Deploy Models\n",
        "5. `Flask` => web framework written in Python"
      ],
      "metadata": {
        "id": "iWKZUhuHOdSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Github Essential Guide](https://www.analyticsvidhya.com/blog/2020/05/git-github-essential-guide-beginners/)<br>\n",
        "[Introduction to Linux Commands](https://www.analyticsvidhya.com/blog/2016/08/tutorial-data-science-command-line-scikit-learn/) <br>"
      ],
      "metadata": {
        "id": "MVsN3GzKOdSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>6 Stages of ML Lifecycle<br></h4></center>\n",
        "\n",
        "1. `Problem Definition`\n",
        "2. `Hypothesis Generation`\n",
        "3. `Data Collection`\n",
        "4. `Data Exploration and  Pre-Processing`\n",
        "    * Variable Idenification\n",
        "    * Univariate Analysis\n",
        "    * Bivariate Anaysis\n",
        "    * Missing Value Treatment\n",
        "    * Outlier Treatment\n",
        "    * Variable Transformation\n",
        "5. `Model Building`\n",
        "    * Supervised Learning\n",
        "    * Un-Supervised Learning\n",
        "    * Reinforcement Learning\n",
        "6. `Model Deployment and Monitoring`"
      ],
      "metadata": {
        "id": "ksCTdpOgOdSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h3 style=\"background-color:orange; color:white\" ><br>Project-1 Loan Eligibility Application<br></h3></center>\n",
        "\n",
        "Problem: A bank wants to build an application that can automate Loan Eligibility Process for its customer. In application customer will Fill there details and can chech for the results <br>\n",
        "Bank want to use 4 attributes:\n",
        "* Gender\n",
        "* Maritial Status\n",
        "* Monthly Income in INR\n",
        "* Loan Amount in INR\n",
        "\n",
        "A check buton to see results based on details filled"
      ],
      "metadata": {
        "id": "3vJ2DfIJOdSe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Component of Application<br></h4></center>\n",
        "\n",
        "1. Frontend\n",
        "    * For user interaction\n",
        "    * Desplaying Results => Loan is approved or not\n",
        "2. Backend => can use Google Colab\n",
        "    * Used for Loading data\n",
        "    * data Preprocessing\n",
        "    * Model Building"
      ],
      "metadata": {
        "id": "BdxYeC5vOdSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Frontend of Loan Eligibility App<br></h4></center>\n",
        "\n",
        "We can use:\n",
        "1. HTML with CSS\n",
        "2. Javascript\n",
        "3. `Streamlit` ==> one of rescent option\n",
        "    * Turns data scripts into Shareable web application\n",
        "    * All in python\n",
        "    * No frontend experience required\n",
        "    * Opensource all free\n",
        "    \n",
        "### Why we are using Streamlit for front-end???\n",
        "1. Model Building\n",
        "2. Creating Python Scrip\n",
        "3. Create frontend in Python\n",
        "4. Deploy\n",
        "\n",
        "### Without Streamlit steps will be\n",
        "1. Model Building\n",
        "2. Creating Python Scrip\n",
        "3. Write Flask or other Application\n",
        "4. Create frontend in javascript\n",
        "5. Deploy <br>\n",
        "We will require java and flask knowledge"
      ],
      "metadata": {
        "id": "aNCulD_wOdSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Steps to build Loan Eligibility Application<br></h4></center>\n",
        "\n",
        "1. `Build Frontend of Application` => (Frontend component)\n",
        "2. `Loading and Pre-processing data` => (Backend component)\n",
        "3. `Building model to Automate Loan Eligibility` => (Backend component)\n",
        "\n",
        "#### First make a Simple Rule Based Model:\n",
        "1. If monthly income > 50000, loan approved\n",
        "2. If monthly income > 50000, loan approved....Elif loan amount < 500000, loan approved.....Else loan will be rejected\n",
        "\n",
        "#### ML Model\n"
      ],
      "metadata": {
        "id": "L7yRFBOmOdSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Deploying Rule Based Model using Streamlit<br></h4></center>\n",
        "\n",
        "#### [Available Functions in Streamlit](https://docs.streamlit.io/library/api-reference)\n",
        "\n",
        "Steps:\n",
        "1. Build Frontend of application\n",
        "2. Load data\n",
        "3. Build model to automate Loan Eligibility\n",
        "4. Deploy application\n",
        "\n",
        "As this is rule based model so no need to preprocess the model"
      ],
      "metadata": {
        "id": "wc2LEKwhOdSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Building Frontend of application\n",
        "\n",
        "1.1. `Install Required Libraries` <br>\n",
        "1.2. `Creat Frontend of app using Streamlit`"
      ],
      "metadata": {
        "id": "GAc8IZjvOdSg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.1. `Install Required Libraries` "
      ],
      "metadata": {
        "id": "dRbCxp5lOdSg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "trusted": true,
        "id": "FO-__WeuOdSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#streamlit ==> to define component of application\n",
        "! pip install streamlit"
      ],
      "metadata": {
        "trusted": true,
        "id": "a4036IcIOdSh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pyngrok version"
      ],
      "metadata": {
        "trusted": true,
        "id": "-RLzrmc8OdSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! streamlit version"
      ],
      "metadata": {
        "trusted": true,
        "id": "5wnPePokOdSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`1.2. Creating Frontend of app using Streamlit` \n",
        "\n",
        "[Streamlit Functions](https://docs.streamlit.io/library/api-reference/data)"
      ],
      "metadata": {
        "id": "nFLkqrhiOdSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install writefile"
      ],
      "metadata": {
        "trusted": true,
        "id": "QIwU3aQqOdSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py \n",
        "######### creating python script #########\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "# Function to define out app\n",
        "def main():\n",
        "    #page header\n",
        "    st.markdown('Loan Eligibility Checker')\n",
        "    \n",
        "    ###### 2. loading data ######\n",
        "    \n",
        "    ## creating boxes where user will provide information => we have 4 features in our data\n",
        "    Gender = st.selectbox('Gender',('male','female','other')) # creates a dropdown box\n",
        "    Married = st.selectbox('Marital Status',('married','unmarried','other'))\n",
        "    ApplicantIncome = st.number_input('monthly income in rupees') #numerical input box\n",
        "    LoanAmount = st.number_input('loan amount in rupees')\n",
        "    result = ''\n",
        "    \n",
        "    ## check => if clicked make a prediction and store it\n",
        "    if st.button('Check'):\n",
        "        result = prediction(Gender,Married,ApplicantIncome,LoanAmount) # calling 'prediction' function\n",
        "        st.success(f'Your Loan is: {result}') #display to frontend\n",
        "                           \n",
        "            \n",
        "# defining 'prediction' function => it will predict based on user input data\n",
        "def predict(Gender,Married,ApplicantIncome,LoanAmount):\n",
        "    \n",
        "    ###### 3. building Rule based model to automate Loan eligibility ######\n",
        "    if (ApplicantIncome >=50000): # if loan ApplicantIncome greater or equall to 50k then approve \n",
        "        loan_status = 'Approved'\n",
        "    elif (LoanAmount < 500000): # elif loan amount less then 50 thou then approve\n",
        "        loan_status = 'Approved'\n",
        "    else:\n",
        "        loan_status = 'Rejected'\n",
        "    return loan_status\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "trusted": true,
        "id": "C0dYFtwqOdSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "trusted": true,
        "id": "QivY9CfgOdSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Deploying application"
      ],
      "metadata": {
        "id": "4efV_kt5OdSj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running app\n",
        "!streamlit run app.py >/dev/null"
      ],
      "metadata": {
        "trusted": true,
        "id": "NWNcfhWbOdSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Streamlit host application on 8501 port bydefault <br>\n",
        "This model is running locally for now <br>\n",
        "To make it accessible to everyone(public):\n",
        "* using `pyngrok lib`"
      ],
      "metadata": {
        "id": "m3ffpek_OdSk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# making locally-hosted web application to be publicly accessible\n",
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect(port=8501)\n",
        "public_url"
      ],
      "metadata": {
        "trusted": true,
        "id": "-si9zsFNOdSk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# disconect server use\n",
        "\n",
        "ngrok.kill()"
      ],
      "metadata": {
        "trusted": true,
        "id": "e0LCa8urOdSl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**`NOTE:`**<br>\n",
        "If not working here then you can use manual process:\n",
        "1. Make a app.py file and copy whole code in that (do all this outside of the notebook)\n",
        "2. Run these comands in terminal"
      ],
      "metadata": {
        "id": "ETvZczvQOdSl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Deploying ML Model using Streamlit<br></h4></center>\n",
        "\n",
        "## Steps to build Loan Eligibility model\n",
        "\n",
        "1. Loading dataset\n",
        "2. Pre-processing dataset\n",
        "3. Building Loan Prediction model\n",
        "4. Deploying machine learning model using Streamlit"
      ],
      "metadata": {
        "id": "8jMsEy7mOdSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# required libs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "trusted": true,
        "id": "cne_pb1EOdSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Loading dataset"
      ],
      "metadata": {
        "id": "7Ud7Q5zoOdSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# loading  dataset\n",
        "path = '/kaggle/input/loan-data-final/'\n",
        "data = pd.read_csv(path+'loan_data.csv')\n",
        "data.sample(5)"
      ],
      "metadata": {
        "trusted": true,
        "id": "pcfr95qFOdSm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "trusted": true,
        "id": "DfTmxAcxOdSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Pre-processing"
      ],
      "metadata": {
        "id": "_worndTqOdSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting categories into numbers\n",
        "data['Gender']= data['Gender'].map({'Male':0, 'Female':1})\n",
        "data['Married']= data['Married'].map({'No':0, 'Yes':1})\n",
        "data['Loan_Status']= data['Loan_Status'].map({'N':0, 'Y':1})"
      ],
      "metadata": {
        "trusted": true,
        "id": "knacfGQqOdSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dependent and independent variables\n",
        "X = data[['Gender','Married','ApplicantIncome','LoanAmount']]\n",
        "y = data.Loan_Status"
      ],
      "metadata": {
        "trusted": true,
        "id": "m9oB5p6nOdSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Building Loan Prediction Model"
      ],
      "metadata": {
        "id": "TBznevEVOdSn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing ML model\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# training logistic regression model\n",
        "model = LogisticRegression() \n",
        "model.fit(X,y)"
      ],
      "metadata": {
        "trusted": true,
        "id": "7xY1h0FVOdSn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# saving model \n",
        "import pickle \n",
        "'''\n",
        "Saving model as we will use it when neaded \n",
        "we need not to run model again and times\n",
        "'''\n",
        "\n",
        "pickle_out = open('classifier_model.pkl',mode ='wb')  # wb => write in binary mode\n",
        "pickle.dump(model,pickle_out)  \n",
        "pickle_out.close()"
      ],
      "metadata": {
        "trusted": true,
        "id": "Sttc1XwsOdSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "trusted": true,
        "id": "9cZTbwvgOdSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Deploying machine learning model using Streamlit\n",
        "\n",
        "1. Building Frontend of application\n",
        "2. Loading and Pre-processing data\n",
        "3. Building Machine Learning model to automate Loan Eligibility\n",
        "4. Deploying application"
      ],
      "metadata": {
        "id": "YdAnOjf3OdSo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Building Frontend of application\n",
        "\n",
        "1.1. Installing Required Libraries<br>\n",
        "1.2. Creating Frontend of app using Streamlit"
      ],
      "metadata": {
        "id": "TS8f0AwPOdSo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing pyngrok\n",
        "!pip install -q pyngrok"
      ],
      "metadata": {
        "trusted": true,
        "id": "kw0DYtv-OdSo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# installing streamlit\n",
        "!pip install -q streamlit"
      ],
      "metadata": {
        "trusted": true,
        "id": "yB3_SAIXOdSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1.2. Creating frontend of app using Streamlit"
      ],
      "metadata": {
        "id": "nJVjqrMLOdSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "# importing required libraries\n",
        "import pickle\n",
        "import streamlit as st\n",
        "\n",
        "# loading the trained model\n",
        "path_model = './classifier_model.pkl'\n",
        "pickle_in = open(path_model,'rb')  # rb => read binary file\n",
        "classifier = pickle.load(pickle_in) # loading model in variable\n",
        "\n",
        "# this is main function in which we define our app  \n",
        "def main():       \n",
        "    # header of the page \n",
        "    html_temp = \"\"\" \n",
        "    <div style =\"background-color:orange;padding:13px\"> \n",
        "    <h1 style =\"color:white;text-align:center;\">Check your Loan Eligibility</h1> \n",
        "    </div> \n",
        "    \"\"\"\n",
        "    st.markdown(html_temp,unsafe_allow_html=True) \n",
        "\n",
        "    # creating boxes for user input => data required to make prediction \n",
        "    Gender = st.selectbox('Gender',('Male','Female','Other'))\n",
        "    Married = st.selectbox('Marital Status',('Unmarried','Married','Other')) \n",
        "    ApplicantIncome = st.number_input('Monthly Income in INR') \n",
        "    LoanAmount = st.number_input('Loan Amount in INR')\n",
        "    result =\"\"\n",
        "      \n",
        "    # when 'Check' will be clicked => make prediction and store it \n",
        "    if st.button('Check'): \n",
        "        result = prediction(Gender,Married,ApplicantIncome,LoanAmount) \n",
        "        st.success(f'Your loan is: {result}') # display output to frontend\n",
        " \n",
        "# defining function which will make prediction using data which user inputs \n",
        "def prediction(Gender,Married,ApplicantIncome,LoanAmount): \n",
        "\n",
        "    ########### 2. Loading and Pre-processing data ###########\n",
        "    # as input will be in object changing it into numbers\n",
        "    if Gender == 'Male':\n",
        "        Gender = 0\n",
        "    else:\n",
        "        Gender = 1\n",
        "\n",
        "    if Married == 'Married':\n",
        "        Married = 1\n",
        "    else:\n",
        "        Married = 0\n",
        "\n",
        "    ############ 3. Building ML model to automate Loan Eligibility  ###########\n",
        "    # prediction varible will have output as 0 or 1\n",
        "    prediction = classifier.predict([[Gender,Married,ApplicantIncome,LoanAmount]]) # use of previously made classifier varaible\n",
        "    \n",
        "    # if prediction is 0 reject loan else approve loan\n",
        "    if prediction == 0:\n",
        "        pred = 'Rejected'\n",
        "    else:\n",
        "        pred = 'Approved'\n",
        "    return pred # returning result\n",
        "     \n",
        "if __name__=='__main__': \n",
        "    main()"
      ],
      "metadata": {
        "trusted": true,
        "id": "nFSNP2Y0OdSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Deploying application"
      ],
      "metadata": {
        "id": "UaB1XUmGOdSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running app\n",
        "!streamlit run app.py &>/dev/null&"
      ],
      "metadata": {
        "id": "Oc4xJpB9OdSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making locally-hosted web application to be publicly accessible\n",
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect('8501')\n",
        "public_url"
      ],
      "metadata": {
        "trusted": true,
        "id": "h44MeVJrOdSp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If not working here you can run it using Terminal/CMD"
      ],
      "metadata": {
        "id": "kDjrE69IOdSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### `NOTE`\n",
        "If you are using Google Colab or Kaggle Kernel or Local IDE. It becomes hard to always run them\n",
        "* In term of google colab and Kaggle kernel they shut down after a certain time so to deal with it `we will AWS`\n",
        "\n",
        "Google Colab and Kaggle Kernel's are best for experimentation purpose only, for hosting we will migrate our code to AWS"
      ],
      "metadata": {
        "id": "CBcesFPjOdSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "\n",
        "Computer Vision Project\n",
        "\n",
        "<center> <h2 style=\"background-color:orange; color:white\" ><br>Making and Deploying Image Classification model using AWS & Stremlit (Pytorch)<br></h2></center>\n",
        "\n",
        "`Problem Statement`:<br>\n",
        "What object is in the image say dog or cat...<br>\n",
        "\n",
        "1. I am using a pretrained Deep Learning model ==> `DenseNet`, `trained on ImageNet Dataset`\n",
        "    * ImageNet Dataset have mill of images of thou of objects"
      ],
      "metadata": {
        "id": "4RPqMoD6OdSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps to Build Image Classification Using Deep Learning `Pretrained Mode`:\n",
        "1. Define DL model \n",
        "2. Preprocess data\n",
        "3. See for prediction from model"
      ],
      "metadata": {
        "id": "IkKUOycjOdSq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Defining Deep Learning Model\n"
      ],
      "metadata": {
        "id": "CN7Sd9QyOdSq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# importing required modules\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# importing pytorch related modules\n",
        "import torch\n",
        "from torchvision import transforms\n",
        "from torchvision.models import densenet121"
      ],
      "metadata": {
        "trusted": true,
        "id": "UxR6khIyOdSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining pretrained densenet121 DL model\n",
        "model = densenet121(pretrained=True) # 121 => layers # pretrained = true as it is pretrained on imagenet dataset\n",
        "model.eval()"
      ],
      "metadata": {
        "trusted": true,
        "id": "5mGHusR3OdSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2 Preprocessing Data"
      ],
      "metadata": {
        "id": "pxBt1cINOdSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))"
      ],
      "metadata": {
        "trusted": true,
        "id": "cl_UxJ80OdSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting image path\n",
        "path = '/kaggle/input/images/images/'\n",
        "filename = path + 'dog.jpg'"
      ],
      "metadata": {
        "trusted": true,
        "id": "1iMAF2_COdSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading image using PIL\n",
        "input_image = Image.open(filename) \n",
        "\n",
        "# preprocessing image according to pretrained model\n",
        "preprocess = transforms.Compose(\n",
        "    [transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],std=[0.229,0.224,0.225])]\n",
        ")\n",
        "\n",
        "input_tensor = preprocess(input_image)\n",
        "\n",
        "# creating a mini-batch as expected by model\n",
        "input_batch = input_tensor.unsqueeze(0) \n",
        "\n",
        "# pass input batch to model\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Ggonp2XEOdSr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [Meaning-of-a-mini-batch-in-deep-learning](https://stackoverflow.com/questions/58269460/what-is-the-meaning-of-a-mini-batch-in-deep-learning)"
      ],
      "metadata": {
        "id": "Q362vCM1OdSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this is original image\n",
        "input_image"
      ],
      "metadata": {
        "trusted": true,
        "id": "tNjK26BDOdSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# above image is converted to tensor\n",
        "print(input_tensor.shape)\n",
        "input_tensor"
      ],
      "metadata": {
        "trusted": true,
        "id": "Q-PBKO7MOdSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_batch.shape)\n",
        "input_batch"
      ],
      "metadata": {
        "trusted": true,
        "id": "33MNHOy-OdSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 Getting Prediction\n",
        "To pass this image as class first convert it by applying `Softmax`\n",
        "\n",
        "Apply Softmax function to an n-dimensional input Tensor rescaling them so that elements of n-dimensional output Tensor lie in range: <br> \n",
        "* [0,1] and \n",
        "* sum to 1\n",
        "\n",
        "[Visit this link for activation Fucntion](https://media.geeksforgeeks.org/wp-content/uploads/20190326164502/1265.png)"
      ],
      "metadata": {
        "id": "jwFgKh0SOdSs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# getting prediction by applying softmax\n",
        "\n",
        "pred = torch.nn.functional.softmax(output[0],dim=0).cpu().numpy()\n",
        "np.argmax(pred)"
      ],
      "metadata": {
        "trusted": true,
        "id": "Xqz2ZNfWOdSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`cpu()` moves a tensor back to memory accessible to the CPU\n",
        "* Some operations on tensors cannot be performed on cuda tensors so you need to move them to cpu first\n",
        "\n",
        "* Model was trained on GPU and hence tensors are on GPU\n",
        "    * Now, to perform some operations, like calculating label, we need to move tensor back to CPU and hence we have used .cpu()"
      ],
      "metadata": {
        "id": "YEjT8t79OdSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# downloading classes on which model was trained on \n",
        "!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json"
      ],
      "metadata": {
        "trusted": true,
        "id": "5YDpz9vfOdSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loading classes\n",
        "with open('imagenet_class_index.json','r') as f:\n",
        "    classes = json.load(f) "
      ],
      "metadata": {
        "trusted": true,
        "id": "_U4OVIInOdSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### [argmax basic](https://www.geeksforgeeks.org/numpy-argmax-python/)"
      ],
      "metadata": {
        "id": "Wsqv9RVROdSt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# showing image and its class\n",
        "plt.imshow(input_image)\n",
        "\n",
        "print(classes[str(np.argmax(pred))][1], round(max(pred)*100, 2))"
      ],
      "metadata": {
        "trusted": true,
        "id": "EoQ7zfpgOdSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model is predicting image class as `Labrador_retriever` with `89.73%` confidence \n",
        "\n",
        "---\n",
        "I will also try and experiment with different models and techniques and will observe which will give better results\n",
        "\n",
        "Different approaches I am thinking to try\n",
        "1. Trying a different pretrained model from `torchvision.models` library like `Inception, Mobilenet` \n",
        "2. Taking average prediction from atlest three different Deep Learning models to `Ensemble` them \n",
        "---"
      ],
      "metadata": {
        "id": "Q_kjs-KoOdSt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Deploying Above Model using Streamlit<br></h4></center>\n",
        "\n",
        "STEPS:\n",
        "1. Install required libraries\n",
        "2. Setup DL model using streamlit\n",
        "3. Deploy DL model on Colab\n"
      ],
      "metadata": {
        "id": "A1TuxOEeOdSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Installing required libraries"
      ],
      "metadata": {
        "id": "e6O06ntGOdSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install if required for you\n",
        "!pip install -q streamlit\n",
        "!pip install -q pyngrok"
      ],
      "metadata": {
        "trusted": true,
        "id": "1U0M8P-HOdSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. SettingUp Deep Learning Model using `Streamlit`"
      ],
      "metadata": {
        "id": "KT6tdiHpOdSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download imagenet classes\n",
        "!wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json"
      ],
      "metadata": {
        "id": "_xij8ctNOdSu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why we need to download `imagenet classes`???<br>\n",
        "As imagenet classes will used to represent Classes in string format(i.e. we can read and understand what class a image belong to) rather then numbers\n",
        "\n",
        "----\n",
        "\n",
        "Steps to setup DL or ML model using Streamlit:\n",
        "1. Make a app.py file\n",
        "2. Put code for front and backhand inside app.py file"
      ],
      "metadata": {
        "id": "KZqb0Af0OdSu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "###### Creating Streamlit APP ######\n",
        "import json \n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "from PIL import Image #python imaging library\n",
        "from torchvision import transforms\n",
        "from torchvision.models import densenet121\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "\n",
        "# defining prediction function\n",
        "def predict(image):\n",
        "    model = densenet121(pretrained=True) # loading Deep Learning pretrained model\n",
        "    model.eval()\n",
        "\n",
        "    # loading classes\n",
        "    with open('imagenet_class_index.json','r') as f:\n",
        "        classes = json.load(f)\n",
        "\n",
        "    # preprocessing image\n",
        "    preprocess = transforms.Compose(\n",
        "        [transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485,0.456,0.406], std=[0.229,0.224,0.225])]\n",
        "    )\n",
        "    input_tensor = preprocess(input_image)\n",
        "    input_batch = input_tensor.unsqueeze(0) # creating a mini-batch as expected by model\n",
        "\n",
        "    # getting prediction\n",
        "    with torch.no_grad():\n",
        "        output = model(input_batch) # giving batch to model for prediction\n",
        "\n",
        "    # using softmax function to convert output into classwise probabilities\n",
        "    pred = torch.nn.functional.softmax(output[0],dim=0).cpu().numpy()\n",
        "\n",
        "    # saving confidence and label to return\n",
        "    confidence = round(max(pred)*100, 2)\n",
        "    label = classes[str(np.argmax(pred))][1]\n",
        "    return confidence,label # returning confidence and label\n",
        "\n",
        "# defining an image file uploader\n",
        "image = st.file_uploader('Upload image here') #file_uploader is a streamlit component\n",
        "\n",
        "# defining button for getting prediction\n",
        "if image is not None and st.button('See prediction'):\n",
        "    input_image = Image.open(image) # loading image using PIL\n",
        "    st.image(input_image,use_column_width=True) # showing image using streamlit\n",
        "    confidence,label = predict(input_image) # predict() returns confidence and label\n",
        "    # printing results\n",
        "    print(\"Model is\", confidence, \"% confident that this image is of a\", label)"
      ],
      "metadata": {
        "trusted": true,
        "id": "_Fk9N_xuOdSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`PyTorch uses dynamic computaion graphs from tensors and automatically computes gradient`\n",
        "\n",
        "Py-torch Tensors can also keep track of a computational graph and gradients using `autograd package` which provides automatic differentiation to automate computation of backward passes in neural networks. \n"
      ],
      "metadata": {
        "id": "H0xJ5vfEOdSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3 Deploy Deep Learning model on Colab,kaggle kernel"
      ],
      "metadata": {
        "id": "4KcxcY8ZOdSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running streamlit app\n",
        "!streamlit run app.py >/dev/null"
      ],
      "metadata": {
        "trusted": true,
        "id": "7LLoQkxTOdSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`ngrok allows you to expose a web server running on your local machine to Internet`\n",
        "\n",
        "When you start ngrok, it will display a UI in your terminal with public URL of your tunnel and other status and metrics information about connections made over your tunnel \n"
      ],
      "metadata": {
        "id": "2jGexK4MOdSw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# make streamlit app available publicly using ngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect('8501');\n",
        "\n",
        "public_url"
      ],
      "metadata": {
        "trusted": true,
        "id": "2896rQ7GOdSw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Simply click above link's to see deployment.\n",
        "* if not working use Google Colab with same code"
      ],
      "metadata": {
        "id": "3hQVt3JROdSw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to transfer this model to an AWS system as to deploy this DL model "
      ],
      "metadata": {
        "id": "WCGgN5qrOdSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Deploying Above Model using Streamlit & AWS<br></h4></center>\n",
        "\n",
        "1. Create a AWS instance \n",
        "2. Use Public DNS adress to loging into Instance, use command in terminal/cmd => ssh -i '''path of key''' ubuntu@'''DNS adress''' \n",
        "    * You must be loged in now\n",
        "3. Create a new folder, use this as to deploy dl model => mkdir model_dl => cd model_dl\n",
        "4. Download imagenet classes inside this folder => !wget https://s3.amazonaws.com/deep-learning-models/image-models/imagenet_class_index.json\n",
        "5. create a file name app.py, copy streamlit code into it\n",
        "6. deploy this model => stramlit run app.py\n",
        "    * Click external url, use to open streamlit deploid model in AWS\n",
        "7. Drag dog image it will show class label and %tg for the image"
      ],
      "metadata": {
        "id": "YqAcSZhUOdSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---"
      ],
      "metadata": {
        "id": "93TbCFLfOdSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "NLP Project\n",
        "<center> <h2 style=\"background-color:orange; color:white\" ><br>Project-2 (Typing Master)-textGeneration<br></h2></center>\n",
        "\n",
        "### Steps\n",
        "1. Points on Project\n",
        "2. Creating Front-end\n",
        "3. Building Text Generation Model\n",
        "4. Deploying model using Streamlit and AWS\n",
        "5. Setting up an Accesible website"
      ],
      "metadata": {
        "id": "k1NPm60BOdSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Points on Project\n",
        "* Front-end => Streamlit\n",
        "* Back-end => transformer library from hugging face\n",
        "    * This lib gives pretrained deep learning model \n",
        "    * we will use `GPT2 Model `=> firstly trained on wikipedia dataset and then finetuned on python code\n",
        "* Python code on which model is finetuned on is based on [this](https://github.com/TheAlgorithms/Python) repo\n",
        "\n",
        "### [openai-gpt2-text-generator-python](https://www.analyticsvidhya.com/blog/2019/07/openai-gpt2-text-generator-python/)"
      ],
      "metadata": {
        "id": "Y9VjQtotOdSx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps to make this Typing Master Project\n",
        "1. Deploying model using `Streamlit` on `AWS` ==> (Front-end)\n",
        "    * Insatalling required lib\n",
        "    * Setting up Deep Learning model using Streamlit\n",
        "    * Deploy Deep Learning model on Kaggle kernel if not possible then Google Colab\n",
        "2. Build a `Text Generatin Model` ==> (Back-end)\n",
        "    * Installing required lib\n",
        "    * Define Deep Learning model \n",
        "    * Preprocess data and get prediction\n",
        "    * Deploy Deep Learning model on AWS"
      ],
      "metadata": {
        "id": "KkAzor07OdSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Blueprint of Project\n",
        "1. `Define two classes named as` \n",
        "    * `TypingTutor` => main class used to define both Front & Back End of Project (can say class used for text generation in Streamlit)\n",
        "    * `SessionState` => internall used by website to maintian session per user (can say class used for maintaining session per user)\n",
        "        * everytime user click start buton, a new session is created for user\n",
        "        * untill user will complete all steps, session contin...\n",
        "        \n",
        "2. `TypingTutor Class have these 5 Main Methods used inside it`: (Remember in OOP's function inside a class is called Method)\n",
        "    * `__init__` ==> defines what happens when session starts\n",
        "    * `_code_gen()` ==> function for text generation\n",
        "    * `_get_perf()` ==> function to get typing speed and accuracy\n",
        "    * `on_start_click()` ==> defines what happens when Start button is clicked\n",
        "    * `on_eval_click()` ==> defines what happens when Eval button is clicked\n",
        "    \n",
        "3. `SessionState Class have these 5 variables` (maintained per session)\n",
        "    * `start_time` ==> time when user start writing code\n",
        "    * `end_time` ==> time when user start written code\n",
        "    * `num_chars` ==> number of char to write\n",
        "    * `text` ==> overall code to be written\n",
        "    * `content` ==> code written by user\n",
        " "
      ],
      "metadata": {
        "id": "wzYu1sypOdSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### FlowChart How Website will Work (simplified_v1)\n",
        "1. `Website Starting` --> create instance of class TypingTutor --> calls `__init__()` method, when `__init__()` method is called three things happens one after other \n",
        "    * unique session is created for user\n",
        "    * front-end is create for Website, for user to interact with\n",
        "    * deep learning model is `Initialized` & `Loaded`\n",
        "2. if User Click's `Start` buton --> `on_start_click()` method is called, which leds to three things\n",
        "    * internally call's `_code_gen()` to pick code from example_code.py and generates code for Deep Learning code(example_code.py)\n",
        "    * session state variables like => (start_time,text,num_chars) are Modifies atocode generated\n",
        "    * Updates front-end accordingly\n",
        "    * code generated is shown in leftside of website\n",
        "\n",
        "Code shown to user will be written by use on the right hand side and saved by pressing `Ctrl + Enter`\n",
        "\n",
        "3. Click `Check Speed` button --> `on_eval_click()` method we be called, which leds to three things\n",
        "    * it internally calls `_get_perf()` method to calculate performance i.e. `Speed and Accuracy of typing`\n",
        "    * noe Session state variables specially`(end_time,content)` were modefyied\n",
        "    * front-end accordingly updates i.e. Performance shown to user "
      ],
      "metadata": {
        "id": "Bi65Zk6MOdSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Creating Project Front-end<br></h4></center>\n",
        "\n",
        "Focusing on creating Front-end removing deep learning part for now from flow chart<br>\n",
        "Steps:\n",
        "1. Install required libraries\n",
        "2. Setup Typing Tutor using streamlit\n",
        "3. Deploy Typing Tutor on Colab or Kaggle Kernel if possible"
      ],
      "metadata": {
        "id": "y6v3iZqZOdSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. InstallING required libraries"
      ],
      "metadata": {
        "id": "pPisnDXEOdSy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyngrok\n",
        "!pip install -q streamlit==0.70\n",
        "\n",
        "# streamlit component which gives functionality of coding window\n",
        "!pip install -q streamlit_ace "
      ],
      "metadata": {
        "trusted": true,
        "id": "812JC755OdSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you are using Kaggle Kernel or Google Colab then `restart runtime` before running code\n",
        "\n",
        "1. Go to above `Run`-in kaggle kernel or `Runtime`-in google colab\n",
        "2. Restart runtime"
      ],
      "metadata": {
        "id": "CA2e4oshOdSy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Settingup Typing Tutor using Streamlit\n",
        "`We will use example_code.py file instead of text generation model` for now only, to make it simple"
      ],
      "metadata": {
        "id": "Vce2DfuVOdSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile example_code.py\n",
        "\n",
        "def reverse(x: int) -> int:\n",
        "    \"\"\"\n",
        "    Given a 32-bit signed integer, reverse digits of an integer\n",
        "    \"\"\"\n",
        "    str_num = str(x)\n",
        "    is_negative = False\n",
        "    if str_num[0] == '-':\n",
        "        is_negative = True\n",
        "        str_num = str_num[1:]\n",
        "\n",
        "    sign = '-' if is_negative else '+'\n",
        "    num = int(sign + \"\".join(list(reversed(str_num))))\n",
        "\n",
        "    if -2**31 < num < 2**31-1:\n",
        "        return num\n",
        "    else:\n",
        "        return 0\n",
        "\n",
        "print(reverse(123))"
      ],
      "metadata": {
        "trusted": true,
        "id": "TeNTVfxcOdSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [Why using this `->` notation in Python Code](https://medium.com/@thomas_k_r/whats-this-weird-arrow-notation-in-python-53d9e293113)"
      ],
      "metadata": {
        "id": "6VaIl6Q8OdSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.2. Defining class SessionState file to maintain single session per login\n",
        "\n",
        "##### [Hack to add per-session state to Streamlit](https://gist.github.com/FranzDiebold/898396a6be785d9b5ca6f3706ef9b0bc)"
      ],
      "metadata": {
        "id": "seo-TI71OdSz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile SessionState.py\n",
        "\n",
        "import streamlit.report_thread as ReportThread\n",
        "from streamlit.server.server import Server\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Hack to add per-session state to Streamlit\n",
        "Works for Streamlit >= v0.65\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "class SessionState():\n",
        "    \"\"\"\n",
        "    SessionState: Add per-session state to Streamlit\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        for key, val in kwargs.items():\n",
        "            setattr(self, key, val)\n",
        "\n",
        "\n",
        "def get(**kwargs):\n",
        "    # Hack to get session object from Streamlit\n",
        "    session_id = ReportThread.get_report_ctx().session_id\n",
        "    session_info = Server.get_current()._get_session_info(session_id)\n",
        "\n",
        "    if session_info is None:\n",
        "        raise RuntimeError('Could not get Streamlit session object')\n",
        "\n",
        "    this_session = session_info.session\n",
        "\n",
        "    # Got session object! Now let's attach some state into it\n",
        "    if not hasattr(this_session, '_custom_session_state'):\n",
        "        this_session._custom_session_state = SessionState(**kwargs)\n",
        "\n",
        "    return this_session._custom_session_state"
      ],
      "metadata": {
        "trusted": true,
        "id": "enteYMkpOdSz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2.3. Front-end Creation\n",
        "\n",
        "###### [Use of with statement in python](https://www.geeksforgeeks.org/with-statement-in-python/)"
      ],
      "metadata": {
        "id": "tScgfleDOdS0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "# importing required modules and libraries\n",
        "import time\n",
        "import difflib\n",
        "import textwrap\n",
        "import SessionState\n",
        "import streamlit as st\n",
        "from streamlit_ace import st_ace\n",
        "\n",
        "\n",
        "\n",
        "class TypingTutor:\n",
        "    \"\"\"\n",
        "    Class for text generation in streamlit,\n",
        "    this class will code for both Back & Front-end of project\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        This function defines what happens when website starts i.e. :-\n",
        "        1. Creates session\n",
        "        2. Creates frontend\n",
        "        \"\"\"\n",
        "        ###### STEP-1 ######\n",
        "        ####### Defining Session ######\n",
        "        \"\"\"\n",
        "        utilizing SessionState- Class, defining 5 variable starting from start_time variable\n",
        "        will maintain this info for each session\n",
        "        Naming this state as ==> session_state\n",
        "        \"\"\"\n",
        "        self.session_state = SessionState.get(\n",
        "            name = \"typingSession\",\n",
        "            start_time = 0,\n",
        "            end_time = 0,\n",
        "            num_chars = 0,\n",
        "            text = \"\",\n",
        "            content = \"\",\n",
        "        )\n",
        "\n",
        "        ###### STEP-2 ######\n",
        "        \"\"\"\n",
        "        Creating Front-end Steps:\n",
        "            1. inside set_page_config layout='wide'\n",
        "        \"\"\"\n",
        "        st.set_page_config(page_title=\"Typing Tutor\", layout=\"wide\")\n",
        "\n",
        "        \"\"\"\n",
        "            2. setting title of page\n",
        "        \"\"\"\n",
        "        st.markdown(\"<h1 style='text-align: center; color: black;'>Typing Tutor</h1>\",unsafe_allow_html=True,)\n",
        "\n",
        "        \"\"\"\n",
        "            3. writing hints for new user\n",
        "        \"\"\"\n",
        "        placeholder = st.empty()\n",
        "        with placeholder.beta_container():\n",
        "            st.markdown(\"****\")\n",
        "            st.subheader(\"Steps to check your Typing speed\")\n",
        "            st.write(\n",
        "                \"1. When you are ready, click on start button which will generate code for you to write on left hand side.A point to note that timer starts as soon as you click on start button \")\n",
        "            st.write(\n",
        "                \"2. Start writing same code on code window given on right hand side.When you're done - press 'CTRL + ENTER' to save your code. **Remember to do this as this ensures that code you have written is ready for submission**\")\n",
        "            st.write(\n",
        "                \"3. Lastly, click on Check Speed button to check you writing accuracy and writing speed. Good luck!\")\n",
        "            st.markdown(\"****\")\n",
        "\n",
        "        \"\"\"\n",
        "        Creating two columns\n",
        "            * one for code generated\n",
        "            * other for code to write\n",
        "        Using streamlit beta_columns component as => st.beta_columns(2)\n",
        "        \"\"\"\n",
        "        self.col1, self.col2 = st.beta_columns(2)\n",
        "        \"\"\"\n",
        "        Defining start_button for col1\n",
        "        Setting subheader as Text to write\n",
        "        \"\"\"\n",
        "        with self.col1:\n",
        "            self.start_button = st.button(\"Start!\",key=\"start_button\")\n",
        "            st.subheader(\"Text to write\")\n",
        "        \"\"\"\n",
        "        Defining eval_button for col2\n",
        "        Setting subheader as Text Input\n",
        "        \"\"\"\n",
        "        with self.col2:\n",
        "            self.eval_button = st.button(\"Check Speed\", key=\"eval_button\")\n",
        "            st.subheader(\"Text Input\")\n",
        "            st.write(\"\")\n",
        "\n",
        "            \"\"\"\n",
        "            defining coding window inside 2nd col\n",
        "            Using streamlit ace component as => st_ace() => inside this we will use some arguments to define \n",
        "                our coding window\n",
        "            auto_update = False because we will use CTRL + Enter to update   \n",
        "            \"\"\"\n",
        "            self.session_state.content = st_ace(\n",
        "                placeholder = \"Start typing here ...\",\n",
        "                language = \"python\",\n",
        "                theme = \"solarized_light\",\n",
        "                keybinding = \"sublime\",\n",
        "                font_size = 20,\n",
        "                tab_size = 4,\n",
        "                show_gutter = True,\n",
        "                show_print_margin = True,\n",
        "                wrap = True,\n",
        "                readonly = False,\n",
        "                auto_update = False,\n",
        "                key = \"ace-editor\")\n",
        "\n",
        "    def on_start_click(self):\n",
        "        \"\"\"\n",
        "        This function defines what happens when start button is clicked,\n",
        "            1. Internally calls _code_gen() to generate code\n",
        "            2. Modifies session state variables (start_time, text, num_chars)\n",
        "            3. Updates front-end accordingly\n",
        "            \n",
        "        As every update will take place in col1 or left hand side while start click button will be trigered \n",
        "        so we are using col1 now\n",
        "        \"\"\"\n",
        "        with self.col1:\n",
        "            ###### STEP-1 ######\n",
        "            \"\"\"\n",
        "            Saving generated text\n",
        "            get prediction\n",
        "            \"\"\"\n",
        "            self.session_state.text = self._code_gen()\n",
        "\n",
        "            ###### STEP-2 ######\n",
        "            \"\"\"\n",
        "            modify session state named as:\n",
        "                1. session_state.text\n",
        "                2. session_state.num_chars\n",
        "                3. session_state.start_time\n",
        "            \"\"\"\n",
        "            self.session_state.num_chars = len(self.session_state.text)\n",
        "            self.session_state.start_time = time.time()\n",
        "\n",
        "            ######  STEP-3 ######\n",
        "            \"\"\"\n",
        "            writing code using streamlit on page\n",
        "            Using stremlit.code method as st.code => to write code\n",
        "            Using textwrap.dedent function => to get proper indentation to generated code\n",
        "            \"\"\"\n",
        "            st.code(textwrap.dedent(self.session_state.text))\n",
        "\n",
        "    # defining _code_gen method\n",
        "    def _code_gen(self):\n",
        "        \"\"\"\n",
        "        Function for text generation\n",
        "        \n",
        "        1. Open example_code.py file in read mode\n",
        "        2. Store content of file in variable named as text and return it\n",
        "        \"\"\"\n",
        "        with open(\"example_code.py\", \"r\") as f:\n",
        "            text = \"\".join(f.readlines())\n",
        "        return text\n",
        "\n",
        "    # defining on_eval_click method\n",
        "    def on_eval_click(self):\n",
        "        \"\"\"\n",
        "        This function defines what happens when eval button is clicked\n",
        "            1. Internally calls _get_perf() function to calculate performance\n",
        "            2. Modifies session state variables (end_time, content)\n",
        "            3. Updates front-end accordingly\n",
        "        \"\"\"\n",
        "\n",
        "        ###### STEP-1 ######\n",
        "        \"\"\"\n",
        "        calculating typing speed and accuracy\n",
        "        \n",
        "        calling _get_perf() method, it returns peformance named as:\n",
        "            1. speed => Typing speed\n",
        "            2. accuracy => Typing accuracy\n",
        "        \"\"\"\n",
        "        speed,accuracy = self._get_perf()\n",
        "\n",
        "        ###### STEP-3 ######\n",
        "        \"\"\"\n",
        "        write performance of user using streamlit\n",
        "        \n",
        "        Setting above Typing speed and accuracy to front-end \n",
        "        will calculate Typing speed in WPM=>words per minute\n",
        "        \"\"\"\n",
        "        with self.col1:\n",
        "            st.write(\"Time to write:\",round(speed),\"WPM\")\n",
        "            st.write(\"Accuracy:\",round(accuracy * 100, 2), \"%\")\n",
        "\n",
        "    # _get_perf method will be called internally\n",
        "    def _get_perf(self):\n",
        "        \"\"\"\n",
        "        Function to get accuracy and typing speed\n",
        "        \"\"\"\n",
        "        ###### STEP-2 ######\n",
        "        \"\"\"\n",
        "        it modify session state which is (end_time) here itself\n",
        "        \"\"\"\n",
        "        self.session_state.end_time = time.time() - self.session_state.start_time\n",
        "\n",
        "        \"\"\"\n",
        "        getting typing speed of user \n",
        "        based on num_chars typed and end_time\n",
        "        Typing speed is being calculated in WPM=>words per minute \n",
        "        \"\"\"\n",
        "        speed = ((self.session_state.num_chars / self.session_state.end_time) / 5) * 60\n",
        "\n",
        "        \"\"\"\n",
        "        get typing accuracy of user\n",
        "            comparing two things: generated and written code\n",
        "        using difflib library's SequenceMatcher method for this as => difflib.SequenceMatcher\n",
        "        difflib library => standard library in python\n",
        "        according to comarison done we will take ratio()\n",
        "        return speed and accuracy of typing speed\n",
        "        \"\"\"\n",
        "        accuracy = difflib.SequenceMatcher(None,self.session_state.text,self.session_state.content).ratio()\n",
        "        return speed,accuracy\n",
        "\n",
        "# defining main function\n",
        "if __name__ == \"__main__\":\n",
        "    \"\"\"\n",
        "    creating instance of class inside main function as => TypingTutor() class\n",
        "    \"\"\"\n",
        "    tt = TypingTutor()\n",
        "\n",
        "    \"\"\"\n",
        "    call appropriate method based on button is clicked\n",
        "        Down here if start_button is clicked we are calling on_start_click() method \n",
        "    \"\"\"\n",
        "    if tt.start_button:\n",
        "        tt.on_start_click()\n",
        "\n",
        "    \"\"\"\n",
        "    if eval button is clicked calling for on_eval_click() method\n",
        "    \"\"\"\n",
        "    if tt.eval_button:\n",
        "        tt.on_eval_click()"
      ],
      "metadata": {
        "trusted": true,
        "id": "-ZyFzvYKOdS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some more points on above code:\n",
        "* `class` ==> can be created in Pyton by using keyword `class` \n",
        "    * It is used to create object\n",
        "* `_code_gen() function` => used to generate text\n",
        "* `get_perf() function` => used to calculate speed and accuracy\n",
        "* `on_eval_click() function` internally calls `get_perf() function`\n",
        "    * `on_start_click function` => calles `_code_gen function` and `modify state variables`\n",
        "* `__init__ method` is automatically called when an object/instance of a class is created\n",
        "    * `it allows class to initialize attributes of class`"
      ],
      "metadata": {
        "id": "ZRD931lgOdS0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2.4 Deploying Project on Kaggle or Google Colab"
      ],
      "metadata": {
        "id": "Mj8eS5qBOdS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running streamlit app\n",
        "!streamlit run app.py >/dev/null"
      ],
      "metadata": {
        "trusted": true,
        "id": "T8FrO-ymOdS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making streamlit app available publicly using pyngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect('8501')\n",
        "\n",
        "public_url"
      ],
      "metadata": {
        "trusted": true,
        "id": "7W6gWRIwOdS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Creating Project Back-end<br></h4></center>\n",
        "\n",
        "Now Will create Text Generation Model using a pretrained Deep Learning Model using steps:\n",
        "1. Install required libraries\n",
        "2. Define deep learning model\n",
        "3. Preprocess data and get prediction"
      ],
      "metadata": {
        "id": "qfO3aHMZOdS1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Installing required libraries\n",
        "Will use Huggingface `transfomers` for using pretrained model of text generation"
      ],
      "metadata": {
        "id": "Rbh4siLoOdS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing transformers library by Huggingface\n",
        "!pip install -q transformers "
      ],
      "metadata": {
        "trusted": true,
        "id": "5nOnpP48OdS1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Defining Deep Learning Model"
      ],
      "metadata": {
        "id": "6FYOfHaOOdS1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import required modules\n",
        "\"\"\"\n",
        "importing choice method from random library\n",
        "\"\"\"\n",
        "\n",
        "from random import choice\n",
        "\n",
        "\"\"\"\n",
        "AutoTokenizer module => to preprocess wrt to AutoModelWithLMHead\n",
        "AutoModelWithLMHead module =>  to load pretrained model\n",
        "\"\"\"\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead"
      ],
      "metadata": {
        "trusted": true,
        "id": "nk67Wsl_OdS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# defining pretrained text generation model\n",
        "\"\"\"\n",
        "congcongwang/distilgpt2_fine_tuned_coder => fined tuned GPT-2 model, it is first pretrained on Wikipedia dataset and then finetuned \n",
        "with algorith repos\n",
        "    We are loading both tokenizer and model\n",
        "\"\"\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('congcongwang/distilgpt2_fine_tuned_coder')\n",
        "model = AutoModelWithLMHead.from_pretrained('congcongwang/distilgpt2_fine_tuned_coder')"
      ],
      "metadata": {
        "trusted": true,
        "id": "b4xyhUXyOdS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Preprocess data and getting prediction\n",
        "Lets see how to get prediction from this pretrained model"
      ],
      "metadata": {
        "id": "ScqiH6ZjOdS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting seed text Why???\n",
        "\"\"\"\n",
        "As this is a text generation model it require seed text\n",
        "Seed text => text which is given as an input to out text generation model \n",
        "            so that it can generate text after this seed text\n",
        "\n",
        "For this model we have to give name of function i.e. convert_to_num\n",
        "\"\"\"\n",
        "context = \"def convert_to_num\"\n",
        "\n",
        "# preprocessing seed text How??\n",
        "\"\"\"\n",
        "Using tokenizer which we imported before \n",
        "    Specifying language as python as => \"<python> \"\n",
        "    Passing in seed text as => context\n",
        "Saving preprocessed input into input_ids variable\n",
        "\"\"\"\n",
        "input_ids = tokenizer.encode(\"<python> \" + context, return_tensors='pt')\n",
        "\n",
        "# generate output using model method  => generate\n",
        "\"\"\"\n",
        "As our aim is to produce diff code for diff instance so we have to update hyper-parameter \n",
        "that way only\n",
        "\"\"\"\n",
        "outputs = model.generate(input_ids = input_ids, # passing in input ans after some hyper-parameter\n",
        "                         max_length = 512,     # max length of text generated \n",
        "                         temperature = 0.7,    # variability of text | ranges: 0 to 1 | 1 for most variability\n",
        "                         num_beams = 2,        # ensures diversity of words ranther then char in text\n",
        "                         length_penalty = 1.5) # give variability in text length \n",
        "\n",
        "# decode output to generate text\n",
        "decoded = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
        "print(decoded)"
      ],
      "metadata": {
        "trusted": true,
        "id": "YRtCPVqGOdS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is the code produced, there are some problem in this code:\n",
        "1. This code will produce Syntex Error, but our aim is only to write the code not execution\n",
        "\n",
        "So we are good to go with it"
      ],
      "metadata": {
        "id": "Nw2AxHjBOdS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setting different seed texts Why??\n",
        "\"\"\"\n",
        "To add more variability we are convinced to add more seed texts \n",
        "\"\"\"\n",
        "contexts = [\"def fib\", \"def fact\", \"def sum_of_int\", \"def sum_of_fact\", \"def sum_of_squares\", \"def get_val\", \"def convert_to_num\", \"def get_date\"]\n",
        "\n",
        "# choosing seed text\n",
        "\"\"\"\n",
        "Using choice() method we can choose only one seed at a time\n",
        "\"\"\"\n",
        "context = choice(contexts)\n",
        "\n",
        "# preprocessing seed text\n",
        "input_ids = tokenizer.encode(\"<python> \" + context, return_tensors='pt')\n",
        "\n",
        "# generating output using model\n",
        "outputs = model.generate(input_ids = input_ids,\n",
        "                         max_length = 512,\n",
        "                         temperature = 0.7,\n",
        "                         num_return_sequences = 1,\n",
        "                         num_beams = 2,\n",
        "                         length_penalty = 1.5)\n",
        "\n",
        "# decoding output to generate text\n",
        "decoded = tokenizer.decode(outputs[0],skip_special_tokens=True)\n",
        "print(decoded)"
      ],
      "metadata": {
        "trusted": true,
        "id": "nhQAhtacOdS2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><h5>What you can try more with this model</h5></center><br>\n",
        "\n",
        "You can `try and experiment with different settings and see which of combinations work for you and give better results`<br> \n",
        "Approaching problem statement<br>\n",
        "1. Change `max length` in model generation \n",
        "2. Change `temperature` i.e. variability of model generation \n",
        "3. Change `num_beams` parameter of model generation \n",
        "4. Change `length_penalty` i.e. variability of model generation using  \n",
        "\n",
        "\n",
        "### `Now we have to integrate this Text generation Model to Front-end we have created in past steps`"
      ],
      "metadata": {
        "id": "Fa-fgz2cOdS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center> <h4 style=\"background-color:orange; color:white\" ><br>Integrating Project(Text Generation Model) Front & Back-End with Deployment using Streamlit on AWS<br></h4></center>\n",
        "\n",
        "\n",
        "### 1. Deploying Text Generation model Steps\n",
        "1. Install required libraries\n",
        "2. Setup Deep Learning model using streamlit\n",
        "3. Deploy Deep Learning model on Kaggle(if possible) and Google Colab"
      ],
      "metadata": {
        "id": "eY5YEqaaOdS3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Installing required libraries"
      ],
      "metadata": {
        "id": "ZOveOxntOdS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for pretrained dl model\n",
        "!pip install -q transformers\n",
        "\n",
        "# for deployment on kaggle or colab\n",
        "!pip install -q pyngrok\n",
        "!pip install -q streamlit==0.70\n",
        "\n",
        "# streamlit component for creating coding window for website\n",
        "!pip install -q streamlit_ace "
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T09:24:50.362515Z",
          "iopub.execute_input": "2022-01-03T09:24:50.362866Z",
          "iopub.status.idle": "2022-01-03T09:25:25.808215Z",
          "shell.execute_reply.started": "2022-01-03T09:24:50.362795Z",
          "shell.execute_reply": "2022-01-03T09:25:25.807159Z"
        },
        "trusted": true,
        "id": "d70_rHekOdS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Restart runtime before running code below**"
      ],
      "metadata": {
        "id": "5zGW0OJoOdS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Setup Deep Learning model using streamlit"
      ],
      "metadata": {
        "id": "LtvNCJ1NOdS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining class SessionState file to maintain single session per login"
      ],
      "metadata": {
        "id": "mDFlhcngOdS4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile SessionState.py\n",
        "\n",
        "import streamlit.report_thread as ReportThread\n",
        "from streamlit.server.server import Server\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Hack to add per-session state to Streamlit\n",
        "Works for Streamlit >= v0.65\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "class SessionState():\n",
        "    \"\"\"\n",
        "    SessionState: Add per-session state to Streamlit\n",
        "    \"\"\"\n",
        "    def __init__(self, **kwargs):\n",
        "        for key, val in kwargs.items():\n",
        "            setattr(self, key, val)\n",
        "\n",
        "\n",
        "def get(**kwargs):\n",
        "    # Hack to get session object from Streamlit\n",
        "    session_id = ReportThread.get_report_ctx().session_id\n",
        "    session_info = Server.get_current()._get_session_info(session_id)\n",
        "\n",
        "    if session_info is None:\n",
        "        raise RuntimeError('Could not get Streamlit session object')\n",
        "\n",
        "    this_session = session_info.session\n",
        "\n",
        "    # Got session object! Now let's attach some state into it\n",
        "    if not hasattr(this_session, '_custom_session_state'):\n",
        "        this_session._custom_session_state = SessionState(**kwargs)\n",
        "\n",
        "    return this_session._custom_session_state"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-01-03T09:29:45.863633Z",
          "iopub.execute_input": "2022-01-03T09:29:45.864002Z",
          "iopub.status.idle": "2022-01-03T09:29:45.874615Z",
          "shell.execute_reply.started": "2022-01-03T09:29:45.863965Z",
          "shell.execute_reply": "2022-01-03T09:29:45.873281Z"
        },
        "trusted": true,
        "id": "xgg-iafDOdS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "# importing required modules and libraries\n",
        "import time\n",
        "import difflib\n",
        "import logging   # to debug website\n",
        "import textwrap\n",
        "import SessionState\n",
        "import streamlit as st\n",
        "\n",
        "from random import choice\n",
        "from streamlit_ace import st_ace\n",
        "from tokenizers import AddedToken\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "\n",
        "\n",
        "# defining seed text\n",
        "CONTEXTS = [\n",
        "    \"def fib\",\n",
        "    \"def fact\",\n",
        "    \"def sum_of_int\",\n",
        "    \"def sum_of_fact\",\n",
        "    \"def sum_of_square_error\",\n",
        "    \"def get_val\",\n",
        "    \"def convert_to_num\",\n",
        "    \"def convolute\",\n",
        "    \"def dict_sort\"]\n",
        "\n",
        "# caching _load_model function so that it called only once\n",
        "@st.cache(hash_funcs={st.delta_generator.DeltaGenerator: lambda x: None,AddedToken: lambda x: None,\"_regex.Pattern\": lambda x: None,},allow_output_mutation=True)\n",
        "\n",
        "def _load_model():\n",
        "    \"\"\"\n",
        "    Function to define pretrained text generation model\n",
        "    \"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(\"congcongwang/distilgpt2_fine_tuned_coder\")\n",
        "    model = AutoModelWithLMHead.from_pretrained(\"congcongwang/distilgpt2_fine_tuned_coder\")\n",
        "    model.eval()\n",
        "    return tokenizer,model\n",
        "\n",
        "###################################################################################\n",
        "\n",
        "class TypingTutor:\n",
        "    \"\"\"\n",
        "    Class for text generation in streamlit\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        \"\"\"\n",
        "        This function defines what happens when website starts :-\n",
        "            1. Creates session\n",
        "            2. Creates the frontend \n",
        "            3. Loads DL model\n",
        "        \"\"\"\n",
        "\n",
        "        ###### Step 1 ######\n",
        "        # defining session\n",
        "        self.session_state = SessionState.get(\n",
        "            name=\"typingSession\",\n",
        "            start_time=0,\n",
        "            end_time=0,\n",
        "            num_chars=0,\n",
        "            text=\"\",\n",
        "            content=\"\")\n",
        "\n",
        "        ###### Step 2 ######\n",
        "        # creating frontend\n",
        "        st.set_page_config(page_title=\"Typing Tutor\", layout=\"wide\")\n",
        "\n",
        "        # set title of the page\n",
        "        st.markdown(\"<h1 style='text-align: center; color: black;'>Typing Tutor</h1>\",unsafe_allow_html=True)\n",
        "\n",
        "        # writing hints for a new user\n",
        "        placeholder = st.empty()\n",
        "        with placeholder.beta_container():\n",
        "            st.markdown(\"****\")\n",
        "            st.subheader(\"Steps to check your Typing speed\")\n",
        "            st.write(\"1. When you are ready, click on the start button which will generate code for you to write on the left hand side. A point to note that the timer starts as soon as you click on the start button\")\n",
        "            st.write(\"2. Start writing the same code on the code window given on the right hand side. When you're done - press 'CTRL + ENTER' to save your code. **Remember to do this as this ensures that the code you have written is ready for submission**\")\n",
        "            st.write(\"3. Lastly, click on Check Speed button to check you writing accuracy and the writing speed. Good luck!\")\n",
        "            st.markdown(\"****\")\n",
        "\n",
        "        # creating two columns, one for code generated and other for code to write\n",
        "        self.col1,self.col2 = st.beta_columns(2)\n",
        "\n",
        "        with self.col1:\n",
        "            self.start_button = st.button(\"Start!\",key=\"start_button\")\n",
        "            st.subheader(\"Text to write\")\n",
        "\n",
        "        with self.col2:\n",
        "            self.eval_button = st.button(\"Check Speed\",key=\"eval_button\")\n",
        "            st.subheader(\"Text Input\")\n",
        "            st.write(\"\")\n",
        "\n",
        "            # defining coding window\n",
        "            self.session_state.content = st_ace(\n",
        "                placeholder = \"Start typing here ...\",\n",
        "                language = \"python\",\n",
        "                theme = \"solarized_light\",\n",
        "                keybinding = \"sublime\",\n",
        "                font_size = 20,\n",
        "                tab_size = 4,\n",
        "                show_gutter = True,\n",
        "                show_print_margin = True,\n",
        "                wrap = True,\n",
        "                readonly = False,\n",
        "                auto_update = False,\n",
        "                key = \"ace-editor\")\n",
        "\n",
        "        ###### Step 3 ######\n",
        "        # loading model and store it for use\n",
        "        self.tokenizer, self.model = _load_model()\n",
        "\n",
        "    def on_start_click(self):\n",
        "        \"\"\"\n",
        "        This function defines what happens when start button is clicked,\n",
        "            1. Internally calls _code_gen() to generate code\n",
        "            2. Modifies session state variables (start_time, text, num_chars)\n",
        "            3. Updates the front-end accordingly\n",
        "        \"\"\"\n",
        "        with self.col1:\n",
        "            ###### Step 1 ######\n",
        "            # choosing seed text\n",
        "            context = choice(CONTEXTS)\n",
        "\n",
        "            # getting prediction\n",
        "            self.session_state.text = self._code_gen(context)\n",
        "\n",
        "            ###### Step 2 ######\n",
        "            # modifying session state\n",
        "            self.session_state.num_chars = len(self.session_state.text)\n",
        "            self.session_state.start_time = time.time()\n",
        "\n",
        "            ###### Step 3 ######\n",
        "            # writing code using streamlit on page\n",
        "            st.code(textwrap.dedent(self.session_state.text))\n",
        "\n",
        "        # logging\n",
        "        logging.info(f\"On start click, start time is {self.session_state.start_time}\")\n",
        "        logging.info(f\"On start click, num_chars to type are {self.session_state.num_chars}\")\n",
        "\n",
        "    def _code_gen(self, context):\n",
        "        \"\"\"\n",
        "        Function for DeepLearning model inference\n",
        "        \"\"\"\n",
        "        # preprocessing seed text\n",
        "        input_ids = self.tokenizer.encode(\"<python> \" + context, return_tensors=\"pt\")\n",
        "        # generating output\n",
        "        outputs = self.model.generate(\n",
        "            input_ids=input_ids,\n",
        "            max_length=256,\n",
        "            temperature=0.7,\n",
        "            num_beams=2,\n",
        "            length_penalty=1.5)\n",
        "        # decoding output to generate text\n",
        "        text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "        return text\n",
        "\n",
        "    def on_eval_click(self):\n",
        "        \"\"\"\n",
        "        This function defines what happens when the eval button is clicked\n",
        "            1. Internally calls _get_perf() to calculate performance\n",
        "            2. Modifies session state variables (end_time, content)\n",
        "            3. Updates the front-end accordingly\n",
        "        \"\"\"\n",
        "\n",
        "        ##### Step 1 #####\n",
        "        # calculating typing speed and accuracy\n",
        "        speed, accuracy = self._get_perf()\n",
        "\n",
        "        ##### Step 3 #####\n",
        "        # writing performance of user using streamlit\n",
        "        with self.col1:\n",
        "            st.write(\"Time to write:\", round(speed), \"WPM\")\n",
        "            st.write(\"Accuracy:\", round(accuracy * 100, 2), \"%\")\n",
        "\n",
        "        # logging\n",
        "        logging.info(f\"On eval click, current time is {time.time()}\")\n",
        "        logging.info(f\"On eval click, start time is {self.session_state.start_time}\")\n",
        "        logging.info(f\"On eval click, end time is {self.session_state.end_time}\")\n",
        "        logging.info(f\"On eval click, speed is {speed}\")\n",
        "\n",
        "    def _get_perf(self):\n",
        "        \"\"\"\n",
        "        Function to get accuracy and typing speed\n",
        "        \"\"\"\n",
        "        ##### Step 2 #####\n",
        "        # modifying session state\n",
        "        self.session_state.end_time = time.time() - self.session_state.start_time\n",
        "        # getting typing speed of  user\n",
        "        speed = ((self.session_state.num_chars / self.session_state.end_time) / 5) * 60\n",
        "        # getting typing accuracy of  user\n",
        "        accuracy = difflib.SequenceMatcher(None, self.session_state.text, self.session_state.content).ratio()\n",
        "        return speed, accuracy\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    logging.info(f\"Starting init\")\n",
        "    # creating instance of class\n",
        "    tt = TypingTutor()\n",
        "    logging.info(f\"Done with init\")\n",
        "\n",
        "    # calling appropriate method if start button is clicked\n",
        "    if tt.start_button:\n",
        "        logging.info(f\"Start button clicked at {time.time()}\")\n",
        "        tt.on_start_click()\n",
        "        logging.info(f\"Done with Start button\")\n",
        "\n",
        "    # calling appropriate method if eval button is clicked\n",
        "    if tt.eval_button:\n",
        "        logging.info(f\"Eval button clicked at {time.time()}\")\n",
        "        tt.on_eval_click()\n",
        "        logging.info(f\"Done with Eval button\")"
      ],
      "metadata": {
        "id": "OVwZw6gkOdS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Deploying Deep Learning model on kaggle or Colab"
      ],
      "metadata": {
        "id": "kppCVDOnOdS5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# running streamlit app\n",
        "!streamlit run app.py --logger.level=info >log.txt"
      ],
      "metadata": {
        "id": "h2KTqJsEOdS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# making streamlit app available publicly\n",
        "from pyngrok import ngrok\n",
        "\n",
        "public_url = ngrok.connect('8501');\n",
        "\n",
        "public_url"
      ],
      "metadata": {
        "id": "AdRAZ1_3OdS5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "If these code are not working in Kaggle use Coalb and everything will work so fine.\n",
        "In case of any problem you can msg me"
      ],
      "metadata": {
        "id": "mg5nCtrgOdS5"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tnE64TOEOdS6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}